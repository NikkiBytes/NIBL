{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import glob\n",
    "#import matplotlib\n",
    "import nibabel as nib\n",
    "from nilearn.image import concat_imgs, index_img, smooth_img\n",
    "from nilearn.image import resample_to_img\n",
    "#from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, permutation_test_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from nilearn import image\n",
    "#from nilearn.plotting import plot_stat_map, show\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---STEP 1---\n",
    "#Cncatenate the imagine data into a NIFTI-2 file. \n",
    "#Note: the data does not fit into a NIFTI-1 file, due to large number of subs. \n",
    "\n",
    "#set basepath\n",
    "#basepath=os.path.join('/projects','niblab','data','eric_data','W1','imagine')\n",
    "#outpath = \"/projects/niblab/nilearn_projects\"\n",
    "#make a list of the files to concat\n",
    "basepath= \"/Users/nikkibytes/Documents/testing/ChocoData\"\n",
    "\n",
    "outpath = \"/Users/nikkibytes/Documents/testing/ChocoData\"\n",
    "\n",
    "#all_func = glob.glob(os.path.join(basepath,'level1_grace_edit','cs*++.feat','filtered_func_data.nii.gz'))\n",
    "#half_func = all_func[:67]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---STEP 2---\n",
    "#load & prepare MRI data\n",
    "#load, fxnl, anatomical, & mask for plotting\n",
    "fmri_subjs=os.path.join(basepath, 'concatenated_imagine.nii')\n",
    "average_ana=os.path.join(basepath,'CS_avg_mprage_image.nii.gz')\n",
    "imag_mask=os.path.join(outpath,'power_roimask_4bi.nii.gz')\n",
    "\n",
    "#plot mask (Power ROIs) over anatomical that is defined above\n",
    "#plotting.plot_roi(imag_mask,bg_img=average_ana,cmap='Paired')\n",
    "\n",
    "#load labels for the functional data\n",
    "#stim = os.path.join('/projects','niblab','scripts','nilean_stuff','label_67_sub.csv')\n",
    "stim = os.path.join(basepath,'label_67_sub.csv')\n",
    "\n",
    "labels = np.recfromcsv(stim, delimiter=\",\",encoding='UTF-8')\n",
    "#print(labels)\n",
    "#Its shape corresponds to the number of time-points times the number of voxels in the mask\n",
    "func_df = pd.read_csv(stim, sep=\",\")\n",
    "#Retrieve the behavioral targets, that we are going to predict in the decoding\n",
    "#y_mask = labels['labels']\n",
    "#subs = labels['subs']\n",
    "y_mask =  func_df['labels']\n",
    "subs = func_df['subs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31825,)\n",
      "(7973,)\n",
      "['unapp' 'app']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---STEP 3---\n",
    "#feature selection\n",
    "#To keep only data corresponding to app food or unapp food, we create a mask of the samples belonging to the condition.\n",
    "#condition_mask = np.logical_or(y_mask == b'app',y_mask == b'unapp')\n",
    "condition_mask = func_df[\"labels\"].isin(['app', 'unapp'])\n",
    "print(condition_mask.shape)\n",
    "#y = y_mask[condition_mask]\n",
    "y = y_mask[condition_mask]\n",
    "print(y.shape)\n",
    "\n",
    "#n_conditions = np.size(np.unique(y))\n",
    "print(y.unique())\n",
    "#session = func_df[condition_mask].to_records(index=False)\n",
    "#print(session.dtype.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#prepare the fxnl data. \n",
    "nifti_masker = NiftiMasker(mask_img=imag_mask,\n",
    "                           smoothing_fwhm=4,standardize=True,\n",
    "                           memory_level=0)\n",
    "\n",
    "fmri_trans = nifti_masker.fit_transform(fmri_subjs)\n",
    "#print(fmri_trans)\n",
    "#X = fmri_trans[condition_mask]\n",
    "#subs = subs[condition_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
