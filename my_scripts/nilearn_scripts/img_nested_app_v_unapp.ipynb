{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested decoding of subjects from the chocolate study\n",
    "### Decoding of response to app vs. unapp images using an ANOVA-based feature selection, within the power atlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this imports all the commands needed for the script to work#\n",
    "import os\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import glob\n",
    "#import matplotlib\n",
    "import nibabel as nib\n",
    "from nilearn.image import concat_imgs, index_img, smooth_img\n",
    "from nilearn.image import resample_to_img\n",
    "#from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import LeaveOneLabelOut, cross_val_score, permutation_test_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from nilearn import image\n",
    "#from nilearn.plotting import plot_stat_map, show\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 1---\n",
    "### Concatenate the imagine data into a NIFTI-2 file. \n",
    "### Note: the data does not fit into a NIFTI-1 file, due to large number of subs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sizeof_hdr should be 540; set sizeof_hdr to 540\n",
      "sizeof_hdr should be 540; set sizeof_hdr to 540\n"
     ]
    }
   ],
   "source": [
    "#set basepath\n",
    "basepath= '/Users/nikkibytes/Documents/testing/Nilearn_projects/ChocoData'\n",
    "\n",
    "#make a list of the files to concat\n",
    "all_func = glob.glob(os.path.join(basepath, 'cs*++.feat', 'filtered_func_data.nii.gz'))\n",
    "\n",
    "#load in all the files from the glob above, then convert them from nifti1 to nifti2\n",
    "ni2_funcs = (nib.Nifti2Image.from_image(nib.load(func)) for func in all_func)\n",
    "#concat, this is with nibabel, but should work with nilearn too\n",
    "ni2_concat = nib.concat_images(ni2_funcs, check_affines=False, axis=3)\n",
    "#set the output file name\n",
    "outfile=os.path.join(basepath,'concatenated_imagine.nii')\n",
    "#write the file\n",
    "ni2_concat.to_filename(outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 2---\n",
    "#### load & prepare MRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y mask shape: (31825,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load, fxnl, anatomical, & mask for plotting\n",
    "fmri_subjs=os.path.join(basepath, 'concatenated_imagine.nii')\n",
    "average_ana=os.path.join(basepath,'CS_avg_mprage_image.nii.gz')\n",
    "imag_mask=os.path.join(basepath,'power_roimask_4bi.nii.gz')\n",
    "\n",
    "#plot mask (Power ROIs) over anatomical that is defined above\n",
    "#plotting.plot_roi(imag_mask,bg_img=average_ana,cmap='Paired')\n",
    "\n",
    "#load labels for the functional data\n",
    "stim = os.path.join(basepath,'label_67_sub.csv')\n",
    "labels = np.recfromcsv(stim, delimiter=\",\", encoding='UTF-8')\n",
    "#print(labels)\n",
    "#Its shape corresponds to the number of time-points times the number of voxels in the mask\n",
    "\n",
    "#Retrieve the behavioral targets, that we are going to predict in the decoding\n",
    "y_mask = labels['labels']\n",
    "subs = labels['subs']\n",
    "print(\"y mask shape:\", y_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 3---\n",
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONDITION MASK SIZE: (31825,)\n",
      "Y shape: (7973,)\n",
      "FMRI TRANS SHAPE:  (950, 6223)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#To keep only data corresponding to app food or unapp food, we create a mask of the samples belonging to the condition.\n",
    "condition_mask = np.logical_or(y_mask == 'app',y_mask == 'unapp')\n",
    "print(\"CONDITION MASK SIZE:\", condition_mask.shape)\n",
    "y = y_mask[condition_mask]\n",
    "print(\"Y shape:\", y.shape)\n",
    "n_conditions = np.size(np.unique(y))\n",
    "\n",
    "#prepare the fxnl data. \n",
    "nifti_masker = NiftiMasker(mask_img=imag_mask,\n",
    "                           smoothing_fwhm=4,standardize=True,\n",
    "                           memory=\"nilearn_cache\",memory_level=1)\n",
    "\n",
    "fmri_trans = nifti_masker.fit_transform(fmri_subjs)\n",
    "#print(\"FMRI TRANS: \",fmri_trans[0])\n",
    "print(\"FMRI TRANS SHAPE: \", fmri_trans.shape)\n",
    "#X = fmri_trans[condition_mask]\n",
    "#subs = subs[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
