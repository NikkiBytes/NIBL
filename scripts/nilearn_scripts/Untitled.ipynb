{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from nilearn.image import concat_imgs, index_img, smooth_img\n",
    "from nilearn.image import resample_to_img\n",
    "#from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, permutation_test_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from nilearn import image\n",
    "#from nilearn.plotting import plot_stat_map, show\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cross_validation import LeaveOneLabelOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 1---\n",
    "#Concatenate the imagine data into a NIFTI-2 file.\n",
    "#Note: the data does not fit into a NIFTI-1 file, due to large number of subs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set basepath\n",
    "basepath=os.path.join('/projects','niblab','data','eric_data','W1','imagine')\n",
    "outpath = \"/projects/niblab/nilearn_projects\"\n",
    "#make a list of the files to concat\n",
    "all_func = glob.glob(os.path.join(basepath,'level1_grace_edit','cs*++.feat','filtered_func_data.nii.gz'))\n",
    "half_func = all_func[:67]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 2---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load & prepare MRI data\n",
    "#load, fxnl, anatomical, & mask for plotting\n",
    "fmri_subjs=os.path.join(outpath, 'concatenated_imagine_67.nii')\n",
    "average_ana=os.path.join(outpath,'CS_avg_mprage_image.nii.gz')\n",
    "imag_mask=os.path.join(outpath,'power_roimask_4bi.nii.gz')\n",
    "\n",
    "#plot mask (Power ROIs) over anatomical that is defined above\n",
    "#plotting.plot_roi(imag_mask,bg_img=average_ana,cmap='Paired')\n",
    "\n",
    "#load labels for the functional data\n",
    "stim = os.path.join('/projects','niblab','scripts','nilean_stuff','label_67_sub.csv')\n",
    "#labels = np.recfromcsv(stim, delimiter=\",\",encoding='UTF-8')\n",
    "#print(labels)\n",
    "#Its shape corresponds to the number of time-points times the number of voxels in the mask\n",
    "func_df = pd.read_csv(stim, sep=\",\")\n",
    "#Retrieve the behavioral targets, that we are going to predict in the decoding\n",
    "#y_mask = labels['labels']\n",
    "#subs = labels['subs']\n",
    "y_mask =  func_df['labels']\n",
    "subs = func_df['subs']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---STEP 3---\n",
    "#feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep only data corresponding to app food or unapp food, we create a mask of the samples belonging to the condition.\n",
    "#condition_mask = np.logical_or(y_mask == b'app',y_mask == b'unapp')\n",
    "condition_mask = func_df[\"labels\"].isin(['app', 'unapp'])\n",
    "print(condition_mask.shape)\n",
    "#y = y_mask[condition_mask]\n",
    "y = y_mask[condition_mask]\n",
    "print(y.shape)\n",
    "\n",
    "n_conditions = np.size(np.unique(y))\n",
    "print(n_conditions)\n",
    "#n_conditions = np.size(np.unique(y))\n",
    "print(y.unique())\n",
    "#session = func_df[condition_mask].to_records(index=False)\n",
    "#print(session.dtype.name)\n",
    "#prepare the fxnl data.\n",
    "nifti_masker = NiftiMasker(mask_img=imag_mask,\n",
    "                           smoothing_fwhm=4,standardize=True,\n",
    "                           memory_level=0)\n",
    "\n",
    "fmri_trans = nifti_masker.fit_transform(fmri_subjs)\n",
    "print(fmri_trans)\n",
    "X = fmri_trans[condition_mask]\n",
    "subs = subs[condition_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(fmri_trans)\n",
    "[[ 0.5087769   0.27887663  0.3514245  ...  2.459353    3.7311056\n",
    "   3.9869728 ]\n",
    " [ 0.48385125  0.29370055  0.35507813 ...  2.5287416   3.6351027\n",
    "   3.9535809 ]\n",
    " [ 0.5118701   0.34580636  0.34771594 ...  2.5323887   3.7883573\n",
    "   4.0834546 ]\n",
    " ...\n",
    " [-0.20601459  1.0056752  -0.14867683 ... -0.24131215 -0.262366\n",
    "  -0.26612085]\n",
    " [-0.22412705  1.0654575  -0.16013078 ... -0.24127465 -0.26207733\n",
    "  -0.26604658]\n",
    " [-0.23273358  1.0431011  -0.17234245 ... -0.24135125 -0.26185337\n",
    "  -0.26517907]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ---STEP 4---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting prediction  & testing the classifer\n",
    "#Define the prediction function to be used. Here we use a Support Vector Classification, with a linear kernel\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "print(svc)\n",
    "feature_selection = SelectKBest(f_classif, k=500)\n",
    "# We have our classifier (SVC),\n",
    "# our feature selection (SelectKBest),\n",
    "# and now, we can plug them together in a *pipeline*\n",
    "# that performs the two operations successively.\n",
    "anova_svc = Pipeline([('anova',feature_selection), ('svc',svc)])\n",
    "#fit the decoder and predict\n",
    "anova_svc.fit(X, y)\n",
    "y_pred = anova_svc.predict(X)\n",
    "cv = LeaveOneLabelOut(subs[subs < 10 ])\n",
    "k_range = [10, 15, 30, 50 , 150, 300, 500, 1000, 1500, 3000, 5000]\n",
    "#cv_scores = cross_val_score(anova_svc, X[subs ==1], y[subs ==1])\n",
    "cv_scores = []\n",
    "scores_validation = []\n",
    "cv_means =[]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
